{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>gmean_Valence</th>\n",
       "      <th>wtd_gmean_Valence</th>\n",
       "      <th>entropy_Valence</th>\n",
       "      <th>wtd_entropy_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>std_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.862692</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.116612</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.062396</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>31.794921</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.219783</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.066221</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.437059</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>92.729214</td>\n",
       "      <td>58.518416</td>\n",
       "      <td>73.132787</td>\n",
       "      <td>36.396602</td>\n",
       "      <td>1.449309</td>\n",
       "      <td>1.057755</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>36.161939</td>\n",
       "      <td>47.094633</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>1.888175</td>\n",
       "      <td>2.210679</td>\n",
       "      <td>1.557113</td>\n",
       "      <td>1.047221</td>\n",
       "      <td>2</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.468606</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.885242</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.122509</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>0.975980</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>35.741099</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.271429</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.232679</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.029175</td>\n",
       "      <td>1</td>\n",
       "      <td>1.114286</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.444697</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.873967</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.119560</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.022291</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>33.768010</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.264286</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.226222</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.048834</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.440952</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.840143</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.110716</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.129224</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>27.848743</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.242857</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.206963</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.096052</td>\n",
       "      <td>1</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.428809</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass   \n",
       "0                   4         88.944468             57.862692  \\\n",
       "1                   5         92.729214             58.518416   \n",
       "2                   4         88.944468             57.885242   \n",
       "3                   4         88.944468             57.873967   \n",
       "4                   4         88.944468             57.840143   \n",
       "\n",
       "   gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass   \n",
       "0          66.361592              36.116612             1.181795  \\\n",
       "1          73.132787              36.396602             1.449309   \n",
       "2          66.361592              36.122509             1.181795   \n",
       "3          66.361592              36.119560             1.181795   \n",
       "4          66.361592              36.110716             1.181795   \n",
       "\n",
       "   wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass   \n",
       "0                 1.062396          122.90607              31.794921  \\\n",
       "1                 1.057755          122.90607              36.161939   \n",
       "2                 0.975980          122.90607              35.741099   \n",
       "3                 1.022291          122.90607              33.768010   \n",
       "4                 1.129224          122.90607              27.848743   \n",
       "\n",
       "   std_atomic_mass  ...  wtd_mean_Valence  gmean_Valence  wtd_gmean_Valence   \n",
       "0        51.968828  ...          2.257143       2.213364           2.219783  \\\n",
       "1        47.094633  ...          2.257143       1.888175           2.210679   \n",
       "2        51.968828  ...          2.271429       2.213364           2.232679   \n",
       "3        51.968828  ...          2.264286       2.213364           2.226222   \n",
       "4        51.968828  ...          2.242857       2.213364           2.206963   \n",
       "\n",
       "   entropy_Valence  wtd_entropy_Valence  range_Valence  wtd_range_Valence   \n",
       "0         1.368922             1.066221              1           1.085714  \\\n",
       "1         1.557113             1.047221              2           1.128571   \n",
       "2         1.368922             1.029175              1           1.114286   \n",
       "3         1.368922             1.048834              1           1.100000   \n",
       "4         1.368922             1.096052              1           1.057143   \n",
       "\n",
       "   std_Valence  wtd_std_Valence  critical_temp  \n",
       "0     0.433013         0.437059           29.0  \n",
       "1     0.632456         0.468606           26.0  \n",
       "2     0.433013         0.444697           19.0  \n",
       "3     0.433013         0.440952           22.0  \n",
       "4     0.433013         0.428809           23.0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_data=pd.read_csv('data/train.csv')\n",
    "temp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number_of_elements</th>\n",
       "      <td>21263.0</td>\n",
       "      <td>4.115224</td>\n",
       "      <td>1.439295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <td>21263.0</td>\n",
       "      <td>87.557631</td>\n",
       "      <td>29.676497</td>\n",
       "      <td>6.941000</td>\n",
       "      <td>72.458076</td>\n",
       "      <td>84.922750</td>\n",
       "      <td>100.404410</td>\n",
       "      <td>208.9804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <td>21263.0</td>\n",
       "      <td>72.988310</td>\n",
       "      <td>33.490406</td>\n",
       "      <td>6.423452</td>\n",
       "      <td>52.143839</td>\n",
       "      <td>60.696571</td>\n",
       "      <td>86.103540</td>\n",
       "      <td>208.9804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <td>21263.0</td>\n",
       "      <td>71.290627</td>\n",
       "      <td>31.030272</td>\n",
       "      <td>5.320573</td>\n",
       "      <td>58.041225</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>78.116681</td>\n",
       "      <td>208.9804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <td>21263.0</td>\n",
       "      <td>58.539916</td>\n",
       "      <td>36.651067</td>\n",
       "      <td>1.960849</td>\n",
       "      <td>35.248990</td>\n",
       "      <td>39.918385</td>\n",
       "      <td>73.113234</td>\n",
       "      <td>208.9804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>range_Valence</th>\n",
       "      <td>21263.0</td>\n",
       "      <td>2.041010</td>\n",
       "      <td>1.242345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <td>21263.0</td>\n",
       "      <td>1.483007</td>\n",
       "      <td>0.978176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.921454</td>\n",
       "      <td>1.063077</td>\n",
       "      <td>1.918400</td>\n",
       "      <td>6.9922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_Valence</th>\n",
       "      <td>21263.0</td>\n",
       "      <td>0.839342</td>\n",
       "      <td>0.484676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451754</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wtd_std_Valence</th>\n",
       "      <td>21263.0</td>\n",
       "      <td>0.673987</td>\n",
       "      <td>0.455580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306892</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.020436</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>critical_temp</th>\n",
       "      <td>21263.0</td>\n",
       "      <td>34.421219</td>\n",
       "      <td>34.254362</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>5.365000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>185.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count       mean        std       min        25%   \n",
       "number_of_elements     21263.0   4.115224   1.439295  1.000000   3.000000  \\\n",
       "mean_atomic_mass       21263.0  87.557631  29.676497  6.941000  72.458076   \n",
       "wtd_mean_atomic_mass   21263.0  72.988310  33.490406  6.423452  52.143839   \n",
       "gmean_atomic_mass      21263.0  71.290627  31.030272  5.320573  58.041225   \n",
       "wtd_gmean_atomic_mass  21263.0  58.539916  36.651067  1.960849  35.248990   \n",
       "...                        ...        ...        ...       ...        ...   \n",
       "range_Valence          21263.0   2.041010   1.242345  0.000000   1.000000   \n",
       "wtd_range_Valence      21263.0   1.483007   0.978176  0.000000   0.921454   \n",
       "std_Valence            21263.0   0.839342   0.484676  0.000000   0.451754   \n",
       "wtd_std_Valence        21263.0   0.673987   0.455580  0.000000   0.306892   \n",
       "critical_temp          21263.0  34.421219  34.254362  0.000210   5.365000   \n",
       "\n",
       "                             50%         75%       max  \n",
       "number_of_elements      4.000000    5.000000    9.0000  \n",
       "mean_atomic_mass       84.922750  100.404410  208.9804  \n",
       "wtd_mean_atomic_mass   60.696571   86.103540  208.9804  \n",
       "gmean_atomic_mass      66.361592   78.116681  208.9804  \n",
       "wtd_gmean_atomic_mass  39.918385   73.113234  208.9804  \n",
       "...                          ...         ...       ...  \n",
       "range_Valence           2.000000    3.000000    6.0000  \n",
       "wtd_range_Valence       1.063077    1.918400    6.9922  \n",
       "std_Valence             0.800000    1.200000    3.0000  \n",
       "wtd_std_Valence         0.500000    1.020436    3.0000  \n",
       "critical_temp          20.000000   63.000000  185.0000  \n",
       "\n",
       "[82 rows x 8 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21263, 82)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=temp_data.drop('critical_temp',axis=1)\n",
    "y=np.sqrt(temp_data['critical_temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wtd_gmean_atomic_mass',\n",
       " 'std_atomic_mass',\n",
       " 'gmean_fie',\n",
       " 'wtd_gmean_fie',\n",
       " 'entropy_fie',\n",
       " 'std_fie',\n",
       " 'wtd_gmean_atomic_radius',\n",
       " 'entropy_atomic_radius',\n",
       " 'wtd_entropy_atomic_radius',\n",
       " 'std_atomic_radius',\n",
       " 'wtd_std_atomic_radius',\n",
       " 'wtd_gmean_Density',\n",
       " 'std_Density',\n",
       " 'std_ElectronAffinity',\n",
       " 'wtd_gmean_FusionHeat',\n",
       " 'std_FusionHeat',\n",
       " 'std_ThermalConductivity',\n",
       " 'wtd_std_ThermalConductivity',\n",
       " 'gmean_Valence',\n",
       " 'wtd_gmean_Valence',\n",
       " 'entropy_Valence',\n",
       " 'wtd_entropy_Valence',\n",
       " 'std_Valence']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix=X.corr().abs()\n",
    "upper=corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(bool))\n",
    "to_drop=[col for col in X.columns if any(upper[col]>.95)]\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>wtd_std_atomic_mass</th>\n",
       "      <th>mean_fie</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_gmean_ThermalConductivity</th>\n",
       "      <th>entropy_ThermalConductivity</th>\n",
       "      <th>wtd_entropy_ThermalConductivity</th>\n",
       "      <th>range_ThermalConductivity</th>\n",
       "      <th>wtd_range_ThermalConductivity</th>\n",
       "      <th>mean_Valence</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.862692</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.062396</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>31.794921</td>\n",
       "      <td>53.622535</td>\n",
       "      <td>775.425000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621979</td>\n",
       "      <td>0.308148</td>\n",
       "      <td>0.262848</td>\n",
       "      <td>399.97342</td>\n",
       "      <td>57.127669</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>0.437059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>92.729214</td>\n",
       "      <td>58.518416</td>\n",
       "      <td>73.132787</td>\n",
       "      <td>1.449309</td>\n",
       "      <td>1.057755</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>36.161939</td>\n",
       "      <td>53.979870</td>\n",
       "      <td>766.440000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619735</td>\n",
       "      <td>0.847404</td>\n",
       "      <td>0.567706</td>\n",
       "      <td>429.97342</td>\n",
       "      <td>51.413383</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>2</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>0.468606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.885242</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>0.975980</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>35.741099</td>\n",
       "      <td>53.656268</td>\n",
       "      <td>775.425000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619095</td>\n",
       "      <td>0.308148</td>\n",
       "      <td>0.250477</td>\n",
       "      <td>399.97342</td>\n",
       "      <td>57.127669</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.271429</td>\n",
       "      <td>1</td>\n",
       "      <td>1.114286</td>\n",
       "      <td>0.444697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.873967</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.022291</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>33.768010</td>\n",
       "      <td>53.639405</td>\n",
       "      <td>775.425000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620535</td>\n",
       "      <td>0.308148</td>\n",
       "      <td>0.257045</td>\n",
       "      <td>399.97342</td>\n",
       "      <td>57.127669</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.264286</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.440952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.840143</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.129224</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>27.848743</td>\n",
       "      <td>53.588771</td>\n",
       "      <td>775.425000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.624878</td>\n",
       "      <td>0.308148</td>\n",
       "      <td>0.272820</td>\n",
       "      <td>399.97342</td>\n",
       "      <td>57.127669</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.242857</td>\n",
       "      <td>1</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>0.428809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21258</th>\n",
       "      <td>4</td>\n",
       "      <td>106.957877</td>\n",
       "      <td>53.095769</td>\n",
       "      <td>82.515384</td>\n",
       "      <td>1.177145</td>\n",
       "      <td>1.254119</td>\n",
       "      <td>146.88130</td>\n",
       "      <td>15.504479</td>\n",
       "      <td>43.202659</td>\n",
       "      <td>661.775000</td>\n",
       "      <td>...</td>\n",
       "      <td>95.001493</td>\n",
       "      <td>1.029002</td>\n",
       "      <td>0.634332</td>\n",
       "      <td>134.00000</td>\n",
       "      <td>83.048889</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168889</td>\n",
       "      <td>0.496904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21259</th>\n",
       "      <td>5</td>\n",
       "      <td>92.266740</td>\n",
       "      <td>49.021367</td>\n",
       "      <td>64.812662</td>\n",
       "      <td>1.323287</td>\n",
       "      <td>1.571630</td>\n",
       "      <td>188.38390</td>\n",
       "      <td>7.353333</td>\n",
       "      <td>50.148287</td>\n",
       "      <td>747.780000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.577047</td>\n",
       "      <td>0.949904</td>\n",
       "      <td>0.745515</td>\n",
       "      <td>399.97342</td>\n",
       "      <td>76.176553</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.047619</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.212959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21260</th>\n",
       "      <td>2</td>\n",
       "      <td>99.663190</td>\n",
       "      <td>95.609104</td>\n",
       "      <td>99.433882</td>\n",
       "      <td>0.690847</td>\n",
       "      <td>0.530198</td>\n",
       "      <td>13.51362</td>\n",
       "      <td>53.041104</td>\n",
       "      <td>5.405448</td>\n",
       "      <td>733.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>57.038314</td>\n",
       "      <td>0.683870</td>\n",
       "      <td>0.559446</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21261</th>\n",
       "      <td>2</td>\n",
       "      <td>99.663190</td>\n",
       "      <td>97.095602</td>\n",
       "      <td>99.433882</td>\n",
       "      <td>0.690847</td>\n",
       "      <td>0.640883</td>\n",
       "      <td>13.51362</td>\n",
       "      <td>31.115202</td>\n",
       "      <td>6.249958</td>\n",
       "      <td>733.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.781651</td>\n",
       "      <td>0.683870</td>\n",
       "      <td>0.659671</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>0.462493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21262</th>\n",
       "      <td>3</td>\n",
       "      <td>87.468333</td>\n",
       "      <td>86.858500</td>\n",
       "      <td>82.555758</td>\n",
       "      <td>1.041270</td>\n",
       "      <td>0.895229</td>\n",
       "      <td>71.75500</td>\n",
       "      <td>43.144000</td>\n",
       "      <td>33.927941</td>\n",
       "      <td>856.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>12.919996</td>\n",
       "      <td>0.194158</td>\n",
       "      <td>0.142553</td>\n",
       "      <td>78.48000</td>\n",
       "      <td>39.448000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21263 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass   \n",
       "0                       4         88.944468             57.862692  \\\n",
       "1                       5         92.729214             58.518416   \n",
       "2                       4         88.944468             57.885242   \n",
       "3                       4         88.944468             57.873967   \n",
       "4                       4         88.944468             57.840143   \n",
       "...                   ...               ...                   ...   \n",
       "21258                   4        106.957877             53.095769   \n",
       "21259                   5         92.266740             49.021367   \n",
       "21260                   2         99.663190             95.609104   \n",
       "21261                   2         99.663190             97.095602   \n",
       "21262                   3         87.468333             86.858500   \n",
       "\n",
       "       gmean_atomic_mass  entropy_atomic_mass  wtd_entropy_atomic_mass   \n",
       "0              66.361592             1.181795                 1.062396  \\\n",
       "1              73.132787             1.449309                 1.057755   \n",
       "2              66.361592             1.181795                 0.975980   \n",
       "3              66.361592             1.181795                 1.022291   \n",
       "4              66.361592             1.181795                 1.129224   \n",
       "...                  ...                  ...                      ...   \n",
       "21258          82.515384             1.177145                 1.254119   \n",
       "21259          64.812662             1.323287                 1.571630   \n",
       "21260          99.433882             0.690847                 0.530198   \n",
       "21261          99.433882             0.690847                 0.640883   \n",
       "21262          82.555758             1.041270                 0.895229   \n",
       "\n",
       "       range_atomic_mass  wtd_range_atomic_mass  wtd_std_atomic_mass   \n",
       "0              122.90607              31.794921            53.622535  \\\n",
       "1              122.90607              36.161939            53.979870   \n",
       "2              122.90607              35.741099            53.656268   \n",
       "3              122.90607              33.768010            53.639405   \n",
       "4              122.90607              27.848743            53.588771   \n",
       "...                  ...                    ...                  ...   \n",
       "21258          146.88130              15.504479            43.202659   \n",
       "21259          188.38390               7.353333            50.148287   \n",
       "21260           13.51362              53.041104             5.405448   \n",
       "21261           13.51362              31.115202             6.249958   \n",
       "21262           71.75500              43.144000            33.927941   \n",
       "\n",
       "         mean_fie  ...  wtd_gmean_ThermalConductivity   \n",
       "0      775.425000  ...                       0.621979  \\\n",
       "1      766.440000  ...                       0.619735   \n",
       "2      775.425000  ...                       0.619095   \n",
       "3      775.425000  ...                       0.620535   \n",
       "4      775.425000  ...                       0.624878   \n",
       "...           ...  ...                            ...   \n",
       "21258  661.775000  ...                      95.001493   \n",
       "21259  747.780000  ...                       1.577047   \n",
       "21260  733.550000  ...                      57.038314   \n",
       "21261  733.550000  ...                      58.781651   \n",
       "21262  856.166667  ...                      12.919996   \n",
       "\n",
       "       entropy_ThermalConductivity  wtd_entropy_ThermalConductivity   \n",
       "0                         0.308148                         0.262848  \\\n",
       "1                         0.847404                         0.567706   \n",
       "2                         0.308148                         0.250477   \n",
       "3                         0.308148                         0.257045   \n",
       "4                         0.308148                         0.272820   \n",
       "...                            ...                              ...   \n",
       "21258                     1.029002                         0.634332   \n",
       "21259                     0.949904                         0.745515   \n",
       "21260                     0.683870                         0.559446   \n",
       "21261                     0.683870                         0.659671   \n",
       "21262                     0.194158                         0.142553   \n",
       "\n",
       "       range_ThermalConductivity  wtd_range_ThermalConductivity  mean_Valence   \n",
       "0                      399.97342                      57.127669          2.25  \\\n",
       "1                      429.97342                      51.413383          2.00   \n",
       "2                      399.97342                      57.127669          2.25   \n",
       "3                      399.97342                      57.127669          2.25   \n",
       "4                      399.97342                      57.127669          2.25   \n",
       "...                          ...                            ...           ...   \n",
       "21258                  134.00000                      83.048889          3.25   \n",
       "21259                  399.97342                      76.176553          2.20   \n",
       "21260                   17.00000                      29.000000          4.50   \n",
       "21261                   17.00000                      15.250000          4.50   \n",
       "21262                   78.48000                      39.448000          5.00   \n",
       "\n",
       "       wtd_mean_Valence  range_Valence  wtd_range_Valence  wtd_std_Valence  \n",
       "0              2.257143              1           1.085714         0.437059  \n",
       "1              2.257143              2           1.128571         0.468606  \n",
       "2              2.271429              1           1.114286         0.444697  \n",
       "3              2.264286              1           1.100000         0.440952  \n",
       "4              2.242857              1           1.057143         0.428809  \n",
       "...                 ...            ...                ...              ...  \n",
       "21258          3.555556              1           2.168889         0.496904  \n",
       "21259          2.047619              1           0.904762         0.212959  \n",
       "21260          4.800000              1           3.200000         0.400000  \n",
       "21261          4.690000              1           2.210000         0.462493  \n",
       "21262          4.500000              3           1.800000         1.500000  \n",
       "\n",
       "[21263 rows x 58 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.drop(to_drop,axis=1,inplace=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>wtd_std_atomic_mass</th>\n",
       "      <th>mean_fie</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_gmean_ThermalConductivity</th>\n",
       "      <th>entropy_ThermalConductivity</th>\n",
       "      <th>wtd_entropy_ThermalConductivity</th>\n",
       "      <th>range_ThermalConductivity</th>\n",
       "      <th>wtd_range_ThermalConductivity</th>\n",
       "      <th>mean_Valence</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.862692</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.062396</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>31.794921</td>\n",
       "      <td>53.622535</td>\n",
       "      <td>775.425000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621979</td>\n",
       "      <td>0.308148</td>\n",
       "      <td>0.262848</td>\n",
       "      <td>399.97342</td>\n",
       "      <td>57.127669</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>0.437059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>92.729214</td>\n",
       "      <td>58.518416</td>\n",
       "      <td>73.132787</td>\n",
       "      <td>1.449309</td>\n",
       "      <td>1.057755</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>36.161939</td>\n",
       "      <td>53.979870</td>\n",
       "      <td>766.440000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619735</td>\n",
       "      <td>0.847404</td>\n",
       "      <td>0.567706</td>\n",
       "      <td>429.97342</td>\n",
       "      <td>51.413383</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>2</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>0.468606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.885242</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>0.975980</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>35.741099</td>\n",
       "      <td>53.656268</td>\n",
       "      <td>775.425000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619095</td>\n",
       "      <td>0.308148</td>\n",
       "      <td>0.250477</td>\n",
       "      <td>399.97342</td>\n",
       "      <td>57.127669</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.271429</td>\n",
       "      <td>1</td>\n",
       "      <td>1.114286</td>\n",
       "      <td>0.444697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.873967</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.022291</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>33.768010</td>\n",
       "      <td>53.639405</td>\n",
       "      <td>775.425000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620535</td>\n",
       "      <td>0.308148</td>\n",
       "      <td>0.257045</td>\n",
       "      <td>399.97342</td>\n",
       "      <td>57.127669</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.264286</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.440952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.840143</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.129224</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>27.848743</td>\n",
       "      <td>53.588771</td>\n",
       "      <td>775.425000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.624878</td>\n",
       "      <td>0.308148</td>\n",
       "      <td>0.272820</td>\n",
       "      <td>399.97342</td>\n",
       "      <td>57.127669</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.242857</td>\n",
       "      <td>1</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>0.428809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21258</th>\n",
       "      <td>4</td>\n",
       "      <td>106.957877</td>\n",
       "      <td>53.095769</td>\n",
       "      <td>82.515384</td>\n",
       "      <td>1.177145</td>\n",
       "      <td>1.254119</td>\n",
       "      <td>146.88130</td>\n",
       "      <td>15.504479</td>\n",
       "      <td>43.202659</td>\n",
       "      <td>661.775000</td>\n",
       "      <td>...</td>\n",
       "      <td>95.001493</td>\n",
       "      <td>1.029002</td>\n",
       "      <td>0.634332</td>\n",
       "      <td>134.00000</td>\n",
       "      <td>83.048889</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168889</td>\n",
       "      <td>0.496904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21259</th>\n",
       "      <td>5</td>\n",
       "      <td>92.266740</td>\n",
       "      <td>49.021367</td>\n",
       "      <td>64.812662</td>\n",
       "      <td>1.323287</td>\n",
       "      <td>1.571630</td>\n",
       "      <td>188.38390</td>\n",
       "      <td>7.353333</td>\n",
       "      <td>50.148287</td>\n",
       "      <td>747.780000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.577047</td>\n",
       "      <td>0.949904</td>\n",
       "      <td>0.745515</td>\n",
       "      <td>399.97342</td>\n",
       "      <td>76.176553</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.047619</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.212959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21260</th>\n",
       "      <td>2</td>\n",
       "      <td>99.663190</td>\n",
       "      <td>95.609104</td>\n",
       "      <td>99.433882</td>\n",
       "      <td>0.690847</td>\n",
       "      <td>0.530198</td>\n",
       "      <td>13.51362</td>\n",
       "      <td>53.041104</td>\n",
       "      <td>5.405448</td>\n",
       "      <td>733.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>57.038314</td>\n",
       "      <td>0.683870</td>\n",
       "      <td>0.559446</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21261</th>\n",
       "      <td>2</td>\n",
       "      <td>99.663190</td>\n",
       "      <td>97.095602</td>\n",
       "      <td>99.433882</td>\n",
       "      <td>0.690847</td>\n",
       "      <td>0.640883</td>\n",
       "      <td>13.51362</td>\n",
       "      <td>31.115202</td>\n",
       "      <td>6.249958</td>\n",
       "      <td>733.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.781651</td>\n",
       "      <td>0.683870</td>\n",
       "      <td>0.659671</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>0.462493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21262</th>\n",
       "      <td>3</td>\n",
       "      <td>87.468333</td>\n",
       "      <td>86.858500</td>\n",
       "      <td>82.555758</td>\n",
       "      <td>1.041270</td>\n",
       "      <td>0.895229</td>\n",
       "      <td>71.75500</td>\n",
       "      <td>43.144000</td>\n",
       "      <td>33.927941</td>\n",
       "      <td>856.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>12.919996</td>\n",
       "      <td>0.194158</td>\n",
       "      <td>0.142553</td>\n",
       "      <td>78.48000</td>\n",
       "      <td>39.448000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21258 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass   \n",
       "0                       4         88.944468             57.862692  \\\n",
       "1                       5         92.729214             58.518416   \n",
       "2                       4         88.944468             57.885242   \n",
       "3                       4         88.944468             57.873967   \n",
       "4                       4         88.944468             57.840143   \n",
       "...                   ...               ...                   ...   \n",
       "21258                   4        106.957877             53.095769   \n",
       "21259                   5         92.266740             49.021367   \n",
       "21260                   2         99.663190             95.609104   \n",
       "21261                   2         99.663190             97.095602   \n",
       "21262                   3         87.468333             86.858500   \n",
       "\n",
       "       gmean_atomic_mass  entropy_atomic_mass  wtd_entropy_atomic_mass   \n",
       "0              66.361592             1.181795                 1.062396  \\\n",
       "1              73.132787             1.449309                 1.057755   \n",
       "2              66.361592             1.181795                 0.975980   \n",
       "3              66.361592             1.181795                 1.022291   \n",
       "4              66.361592             1.181795                 1.129224   \n",
       "...                  ...                  ...                      ...   \n",
       "21258          82.515384             1.177145                 1.254119   \n",
       "21259          64.812662             1.323287                 1.571630   \n",
       "21260          99.433882             0.690847                 0.530198   \n",
       "21261          99.433882             0.690847                 0.640883   \n",
       "21262          82.555758             1.041270                 0.895229   \n",
       "\n",
       "       range_atomic_mass  wtd_range_atomic_mass  wtd_std_atomic_mass   \n",
       "0              122.90607              31.794921            53.622535  \\\n",
       "1              122.90607              36.161939            53.979870   \n",
       "2              122.90607              35.741099            53.656268   \n",
       "3              122.90607              33.768010            53.639405   \n",
       "4              122.90607              27.848743            53.588771   \n",
       "...                  ...                    ...                  ...   \n",
       "21258          146.88130              15.504479            43.202659   \n",
       "21259          188.38390               7.353333            50.148287   \n",
       "21260           13.51362              53.041104             5.405448   \n",
       "21261           13.51362              31.115202             6.249958   \n",
       "21262           71.75500              43.144000            33.927941   \n",
       "\n",
       "         mean_fie  ...  wtd_gmean_ThermalConductivity   \n",
       "0      775.425000  ...                       0.621979  \\\n",
       "1      766.440000  ...                       0.619735   \n",
       "2      775.425000  ...                       0.619095   \n",
       "3      775.425000  ...                       0.620535   \n",
       "4      775.425000  ...                       0.624878   \n",
       "...           ...  ...                            ...   \n",
       "21258  661.775000  ...                      95.001493   \n",
       "21259  747.780000  ...                       1.577047   \n",
       "21260  733.550000  ...                      57.038314   \n",
       "21261  733.550000  ...                      58.781651   \n",
       "21262  856.166667  ...                      12.919996   \n",
       "\n",
       "       entropy_ThermalConductivity  wtd_entropy_ThermalConductivity   \n",
       "0                         0.308148                         0.262848  \\\n",
       "1                         0.847404                         0.567706   \n",
       "2                         0.308148                         0.250477   \n",
       "3                         0.308148                         0.257045   \n",
       "4                         0.308148                         0.272820   \n",
       "...                            ...                              ...   \n",
       "21258                     1.029002                         0.634332   \n",
       "21259                     0.949904                         0.745515   \n",
       "21260                     0.683870                         0.559446   \n",
       "21261                     0.683870                         0.659671   \n",
       "21262                     0.194158                         0.142553   \n",
       "\n",
       "       range_ThermalConductivity  wtd_range_ThermalConductivity  mean_Valence   \n",
       "0                      399.97342                      57.127669          2.25  \\\n",
       "1                      429.97342                      51.413383          2.00   \n",
       "2                      399.97342                      57.127669          2.25   \n",
       "3                      399.97342                      57.127669          2.25   \n",
       "4                      399.97342                      57.127669          2.25   \n",
       "...                          ...                            ...           ...   \n",
       "21258                  134.00000                      83.048889          3.25   \n",
       "21259                  399.97342                      76.176553          2.20   \n",
       "21260                   17.00000                      29.000000          4.50   \n",
       "21261                   17.00000                      15.250000          4.50   \n",
       "21262                   78.48000                      39.448000          5.00   \n",
       "\n",
       "       wtd_mean_Valence  range_Valence  wtd_range_Valence  wtd_std_Valence  \n",
       "0              2.257143              1           1.085714         0.437059  \n",
       "1              2.257143              2           1.128571         0.468606  \n",
       "2              2.271429              1           1.114286         0.444697  \n",
       "3              2.264286              1           1.100000         0.440952  \n",
       "4              2.242857              1           1.057143         0.428809  \n",
       "...                 ...            ...                ...              ...  \n",
       "21258          3.555556              1           2.168889         0.496904  \n",
       "21259          2.047619              1           0.904762         0.212959  \n",
       "21260          4.800000              1           3.200000         0.400000  \n",
       "21261          4.690000              1           2.210000         0.462493  \n",
       "21262          4.500000              3           1.800000         1.500000  \n",
       "\n",
       "[21258 rows x 58 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_index=X.sample(5).index\n",
    "X.iloc[sample_data_index].to_csv('../temp_fastapi/data/sample_data.csv',\n",
    "                   index_label=False)\n",
    "X.drop(sample_data_index,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number_of_elements': 'int',\n",
       " 'mean_atomic_mass': 'float',\n",
       " 'wtd_mean_atomic_mass': 'float',\n",
       " 'gmean_atomic_mass': 'float',\n",
       " 'entropy_atomic_mass': 'float',\n",
       " 'wtd_entropy_atomic_mass': 'float',\n",
       " 'range_atomic_mass': 'float',\n",
       " 'wtd_range_atomic_mass': 'float',\n",
       " 'wtd_std_atomic_mass': 'float',\n",
       " 'mean_fie': 'float',\n",
       " 'wtd_mean_fie': 'float',\n",
       " 'wtd_entropy_fie': 'float',\n",
       " 'range_fie': 'float',\n",
       " 'wtd_range_fie': 'float',\n",
       " 'wtd_std_fie': 'float',\n",
       " 'mean_atomic_radius': 'float',\n",
       " 'wtd_mean_atomic_radius': 'float',\n",
       " 'gmean_atomic_radius': 'float',\n",
       " 'range_atomic_radius': 'int',\n",
       " 'wtd_range_atomic_radius': 'float',\n",
       " 'mean_Density': 'float',\n",
       " 'wtd_mean_Density': 'float',\n",
       " 'gmean_Density': 'float',\n",
       " 'entropy_Density': 'float',\n",
       " 'wtd_entropy_Density': 'float',\n",
       " 'range_Density': 'float',\n",
       " 'wtd_range_Density': 'float',\n",
       " 'wtd_std_Density': 'float',\n",
       " 'mean_ElectronAffinity': 'float',\n",
       " 'wtd_mean_ElectronAffinity': 'float',\n",
       " 'gmean_ElectronAffinity': 'float',\n",
       " 'wtd_gmean_ElectronAffinity': 'float',\n",
       " 'entropy_ElectronAffinity': 'float',\n",
       " 'wtd_entropy_ElectronAffinity': 'float',\n",
       " 'range_ElectronAffinity': 'float',\n",
       " 'wtd_range_ElectronAffinity': 'float',\n",
       " 'wtd_std_ElectronAffinity': 'float',\n",
       " 'mean_FusionHeat': 'float',\n",
       " 'wtd_mean_FusionHeat': 'float',\n",
       " 'gmean_FusionHeat': 'float',\n",
       " 'entropy_FusionHeat': 'float',\n",
       " 'wtd_entropy_FusionHeat': 'float',\n",
       " 'range_FusionHeat': 'float',\n",
       " 'wtd_range_FusionHeat': 'float',\n",
       " 'wtd_std_FusionHeat': 'float',\n",
       " 'mean_ThermalConductivity': 'float',\n",
       " 'wtd_mean_ThermalConductivity': 'float',\n",
       " 'gmean_ThermalConductivity': 'float',\n",
       " 'wtd_gmean_ThermalConductivity': 'float',\n",
       " 'entropy_ThermalConductivity': 'float',\n",
       " 'wtd_entropy_ThermalConductivity': 'float',\n",
       " 'range_ThermalConductivity': 'float',\n",
       " 'wtd_range_ThermalConductivity': 'float',\n",
       " 'mean_Valence': 'float',\n",
       " 'wtd_mean_Valence': 'float',\n",
       " 'range_Valence': 'int',\n",
       " 'wtd_range_Valence': 'float',\n",
       " 'wtd_std_Valence': 'float'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_dict=X.dtypes.to_dict()\n",
    "\n",
    "new_cols={}\n",
    "for col, type in cols_dict.items():\n",
    "    if type == 'int64':\n",
    "        new_cols[col] = 'int'\n",
    "    else:\n",
    "        new_cols[col] = 'float'\n",
    "\n",
    "new_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open('../temp_fastapi/data/cols.json','w') as f:\n",
    "    json.dump(new_cols,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.45794468e-02, 5.75285691e-02, 1.11941873e-01, 1.64589859e-01,\n",
       "        1.71235759e-01, 1.46832846e-01, 1.29283517e-01, 1.03426814e-01,\n",
       "        9.98961795e-02, 1.01142286e-01, 7.61163197e-02, 8.96158035e-02,\n",
       "        9.33541220e-02, 9.14849627e-02, 5.14018803e-02, 5.07788272e-02,\n",
       "        5.35825661e-02, 6.15784142e-02, 7.91277430e-02, 1.17237824e-01,\n",
       "        1.39460051e-01, 1.00311548e-01, 3.11526547e-02, 2.62720722e-02,\n",
       "        1.50571165e-02, 1.06957448e-02, 2.07684365e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.03842182e-04]),\n",
       " array([ 0.01449138,  0.46739068,  0.92028999,  1.37318929,  1.82608859,\n",
       "         2.2789879 ,  2.7318872 ,  3.18478651,  3.63768581,  4.09058512,\n",
       "         4.54348442,  4.99638373,  5.44928303,  5.90218233,  6.35508164,\n",
       "         6.80798094,  7.26088025,  7.71377955,  8.16667886,  8.61957816,\n",
       "         9.07247746,  9.52537677,  9.97827607, 10.43117538, 10.88407468,\n",
       "        11.33697399, 11.78987329, 12.2427726 , 12.6956719 , 13.1485712 ,\n",
       "        13.60147051]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y,bins=30,density=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.3,random_state=36)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping highly correlated predictors and performing dimensionality\n",
    "reduction leads to poor performance for the support vector classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pipe_svr=make_pipeline(StandardScaler(),PCA(n_components=40),LinearSVR())\n",
    "scores=cross_val_score(estimator=pipe_svr,X=X_train,y=y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7326510320519195"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;pca&#x27;, PCA(n_components=40)), (&#x27;linearsvr&#x27;, LinearSVR())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;pca&#x27;, PCA(n_components=40)), (&#x27;linearsvr&#x27;, LinearSVR())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=40)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVR</label><div class=\"sk-toggleable__content\"><pre>LinearSVR()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('pca', PCA(n_components=40)), ('linearsvr', LinearSVR())])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_svr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7228501553250646"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_svr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../temp_fastapi/saved_models/temp_svr_model.joblib']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(pipe_svr,'../temp_fastapi/saved_models/temp_svr_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8959421861392871"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    criterion='squared_error',\n",
    "    n_jobs=-1,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    max_samples=.8,\n",
    "    warm_start=True)\n",
    "\n",
    "scores=cross_val_score(rf,X_train,y_train)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10, max_features=&#x27;sqrt&#x27;, max_samples=0.8,\n",
       "                      n_estimators=500, n_jobs=-1, warm_start=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=10, max_features=&#x27;sqrt&#x27;, max_samples=0.8,\n",
       "                      n_estimators=500, n_jobs=-1, warm_start=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=10, max_features='sqrt', max_samples=0.8,\n",
       "                      n_estimators=500, n_jobs=-1, warm_start=True)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8929392138370831"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../temp_fastapi/saved_models/temp_rf_model.joblib']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf,'../temp_fastapi/saved_models/temp_rf_model.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGbm Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm=lgb.LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    colsample_bytree=.8,\n",
    "    learning_rate=.1,\n",
    "    max_depth=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(colsample_bytree=0.8, n_estimators=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(colsample_bytree=0.8, n_estimators=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(colsample_bytree=0.8, n_estimators=1000)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lgbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9276982583149322"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../temp_fastapi/saved_models/temp_lightgbm_model.joblib']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lgbm,'../temp_fastapi/saved_models/temp_lightgbm_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(colsample_bytree=0.8, n_estimators=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(colsample_bytree=0.8, n_estimators=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(colsample_bytree=0.8, n_estimators=1000)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model=joblib.load('saved_models/temp_lightgbm_model.joblib')\n",
    "test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>wtd_std_atomic_mass</th>\n",
       "      <th>mean_fie</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_gmean_ThermalConductivity</th>\n",
       "      <th>entropy_ThermalConductivity</th>\n",
       "      <th>wtd_entropy_ThermalConductivity</th>\n",
       "      <th>range_ThermalConductivity</th>\n",
       "      <th>wtd_range_ThermalConductivity</th>\n",
       "      <th>mean_Valence</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17925</th>\n",
       "      <td>3</td>\n",
       "      <td>68.587467</td>\n",
       "      <td>80.238047</td>\n",
       "      <td>66.86942</td>\n",
       "      <td>1.072385</td>\n",
       "      <td>0.653102</td>\n",
       "      <td>35.379</td>\n",
       "      <td>58.02375</td>\n",
       "      <td>15.547577</td>\n",
       "      <td>718.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>36.121156</td>\n",
       "      <td>0.973618</td>\n",
       "      <td>0.899664</td>\n",
       "      <td>68.0</td>\n",
       "      <td>21.833333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.383333</td>\n",
       "      <td>2</td>\n",
       "      <td>2.516667</td>\n",
       "      <td>0.896134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass   \n",
       "17925                   3         68.587467             80.238047  \\\n",
       "\n",
       "       gmean_atomic_mass  entropy_atomic_mass  wtd_entropy_atomic_mass   \n",
       "17925           66.86942             1.072385                 0.653102  \\\n",
       "\n",
       "       range_atomic_mass  wtd_range_atomic_mass  wtd_std_atomic_mass   \n",
       "17925             35.379               58.02375            15.547577  \\\n",
       "\n",
       "         mean_fie  ...  wtd_gmean_ThermalConductivity   \n",
       "17925  718.333333  ...                      36.121156  \\\n",
       "\n",
       "       entropy_ThermalConductivity  wtd_entropy_ThermalConductivity   \n",
       "17925                     0.973618                         0.899664  \\\n",
       "\n",
       "       range_ThermalConductivity  wtd_range_ThermalConductivity  mean_Valence   \n",
       "17925                       68.0                      21.833333           3.0  \\\n",
       "\n",
       "       wtd_mean_Valence  range_Valence  wtd_range_Valence  wtd_std_Valence  \n",
       "17925          3.383333              2           2.516667         0.896134  \n",
       "\n",
       "[1 rows x 58 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example=X_test.iloc[[np.random.randint(low=1,high=X_test.shape[0]),]]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.48460108])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.predict(example.to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
